{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodrigo Sennati Mattar \n",
    "\n",
    "Lucca Nazari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Lucca Nazari]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O produto escolhido para ser o objeto de estudo no projeto foram os Airpods, fones de ouvido sem fio da Apple.\n",
    "Como base de dados, importamos 750 para base de treinamento, em que n√≥s classificamos os tweets e mais 250 de teste, para validar a efic√°cia do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'airpods'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 250\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    if msg.full_text.lower()[0] != 'r' and msg.full_text.lower()[1] != 't':\n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(list(set(msgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√≥s dividimos os tweets em 3  classifica√ß√µes diferentes (irrevelante,relevante positivo e relevante negativo). Ao classificar como irrevelante, n√≥s estamos nos referindo a todos os tweets onde n√£o h√° uma cr√≠tica expl√≠cita ao produto (aos que somente mencionam o produto). Em rela√ß√£o a segunda classifica√ß√£o, n√≥s estamos nos referindo aos tweets onde houve uma cr√≠tica negativa expl√≠cita ao produto (como por exemplo os airpods acabam a bateria muito rapido, ou eu perdi meus airpods). A terceira classifica√ß√£o √© para os tweets onde h√° uma cr√≠tica positiva expl√≠cita ao produto (como por exemplo \"eu s√≥ queria um airpods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar os c√≥digos, √© necess√°rio importar as bibliotecas pd (pandas) e np (numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "pd.options.display.max_rows = 13 # Escolher quantos prints as fun√ß√µes do pandas fazem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a leitura dos tweets, √© necess√°rio \"limpar\" o tweet para que n√£o exista influ√™ncia de termos indesejados para a an√°lise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira \"limpeza\" dos tweets foi realizada pela fun√ß√£o cleanup, em que ela recebe uma string e remove todos os sinais de pontua√ß√£o, v√≠rgulas, pontos de interroga√ß√£o e exclama√ß√£o, dois-pontos e etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    punctuation = '[!\\-.:?;,]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, √© necess√°rio importar os tweets do excel, atrav√©s do pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_excel('airpods1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas necess√°rias para o desenvolvimento do c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "from numpy import arange\n",
    "from numpy import percentile\n",
    "import numpy as np\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import string\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, j√° com os tweets importados e classificados, agrupamos todos os tweets em um √∫nico dataframe.\n",
    "Ap√≥s isso, separamos os tweets com base em sua classifica√ß√£o (1,2 ou 3), para facilitar os c√≥digos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTRANDO TODOS OS TWEETS RELEVENATES\n",
    "relev = tweets.loc[:,['Treinamento','Relevante']]\n",
    "#FILTRANDO OS TWEETS DE ACORDO COM SUA RELEVANCIA (=1,=2,=3)\n",
    "relev1 = tweets.loc[tweets.Relevante==1]\n",
    "relev2 = tweets.loc[tweets.Relevante==2]\n",
    "relev3 = tweets.loc[tweets.Relevante==3]\n",
    "texto_relev1_ = relev1.Treinamento\n",
    "texto_relev2_ = relev2.Treinamento\n",
    "texto_relev3_ = relev3.Treinamento\n",
    "texto_relev = relev.Treinamento\n",
    "\n",
    "#SEPARANDO CADA GRUPO DE RELEVANCIA PARA UM ARQUIVO CSV\n",
    "texto_relev1_.to_csv('relev1.csv', header=True, index=False, encoding='utf-8')\n",
    "texto_relev2_.to_csv('relev2.csv', header=True, index=False, encoding='utf-8')\n",
    "texto_relev3_.to_csv('relev3.csv', header=True, index=False, encoding='utf-8')\n",
    "texto_relev.to_csv('relev.csv', header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo com a \"limpeza\" que foi realizada anteriormente, √© necess√°rio remover termos ileg√≠veis para evitar que o c√≥digo d√™ erros.\n",
    "Tal a√ß√£o foi realizada pela fun√ß√£o removetext, abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABRINDO OS ARQUIVOS CSV\n",
    "#primeiro arquivo(relevancia =1)\n",
    "df1 = pd.read_csv('relev1.csv')\n",
    "df1 = df1.dropna(axis=0, how = 'any')\n",
    "#LIMPANDO O TEXTO DE CADA ARQUIVO CSV E DANDO VALUE COUNTS \n",
    "def removetext(text):\n",
    "    return ''.join([i if ord(i) < 128 else '' for i in text])\n",
    "\n",
    "df1['Treinamento'] = df1['Treinamento'].apply(removetext)\n",
    "\n",
    "#segund arquivo(relevancia = 2)\n",
    "df2 = pd.read_csv('relev2.csv')\n",
    "df2 = df2.dropna(axis=0, how = 'any')\n",
    "df2['Treinamento'] = df2['Treinamento'].apply(removetext)\n",
    "\n",
    "\n",
    "#terceiro arquivo (relevancia = 3)\n",
    "df3 = pd.read_csv('relev3.csv')\n",
    "df3 = df3.dropna(axis=0, how = 'any')\n",
    "df3['Treinamento'] = df3['Treinamento'].apply(removetext)\n",
    "\n",
    "#arquivo total\n",
    "dft = pd.read_csv('relev.csv')\n",
    "dft = dft.dropna(axis=0, how = 'any')\n",
    "dft['Treinamento'] = dft['Treinamento'].apply(removetext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, foi desenvolvida a frequ√™ncia relativa das palavras em rela√ß√£o a cada grupo de relev√¢ncia, classificados como 1,2,3 e um grupo que cont√©m todos os tweet analisados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRIANDO A TABELA DE FREQUENCIA RELETIVA PARA CADA GRUPO DE RELEVANCIA DE UM TWEET\n",
    "relev1_array = df1['Treinamento'].str.split(' ', expand=True).stack().value_counts()\n",
    "relev2_array = df2['Treinamento'].str.split(' ', expand=True).stack().value_counts()\n",
    "relev3_array = df3['Treinamento'].str.split(' ', expand=True).stack().value_counts()\n",
    "relev_array = dft['Treinamento'].str.split(' ',expand = True).stack().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, antes de classificar os tweets, √© necess√°rio separar os tweets em palavras isoladas, que possam ser analisadas individualmente. Assim, as palavras pertencentes a um tweet qualquer, s√£o comparadas com √† base de dados, dados do excel j√° classificados, para que possa ser atribu√≠do a um determinado grupo relevante (1,2 ou 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o caso de uma nova palavra, ou seja, uma palavra que n√£o tenha aparecido na base de dados, a fun√ß√£o ir√° dividir 1 pela soma de todas as palavras no determinado grupo em que a palavra n√£o est√° presente com todas as palavras presentes no dataframe. Isso foi feito justamente para que a frequ√™ncia dessa palavra seja muito pequena, visto que por n√£o ter aparecido anteriormente, n√£o ter√° um peso relevante na an√°lise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, para o caso de a palavra j√° presente na base de dados, a probabilidade ser√° a divis√£o da frequ√™ncia relativa da palavra em seu grupo relativo espec√≠fico pela soma de todas as palavras do grupo espec√≠fico com todas as palavras analisadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ap√≥s isso, o algoritmo compara as probabilidades encontradas de o tweet, soma de palavras, estar em cada grupo espec√≠fico.\n",
    "Como resposta, a fun√ß√£o retorna a maior probabilidade entre os tr√äs grupos relevantes. Logo, o tweet ter√° sido classificado como mais prov√°vel de ser um tweet irrelevante (1), tweet relevante com cr√≠tica negativa (2) ou tweet relevante com cr√≠tica positiva (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROBABILIDADE DE UMA PALAVRA EM UM TWEET ALEATORIO (VERIFICAR REPETIDAS)\n",
    "P1 = 1\n",
    "P2 = 1 \n",
    "P3 = 1\n",
    "\n",
    "def robo(tweet_teste,P1,P2,P3):\n",
    "    tweet_teste = str(tweet_teste)\n",
    "    tweet_teste = tweet_teste.lower()\n",
    "    tweet_teste = cleanup(tweet_teste)\n",
    "    tweet_teste = removetext(tweet_teste)\n",
    "    tweet_teste = pd.Series(tweet_teste.split())\n",
    "    lista_tweet = list(tweet_teste)\n",
    "    for palavra in lista_tweet:\n",
    "        if palavra not in relev1_array:\n",
    "            P1*=1/(sum(relev1_array)+len(relev_array))\n",
    "        else: \n",
    "            P1*=(relev1_array[palavra]+1)/(sum(relev1_array)+len(relev_array))\n",
    "        if palavra not in relev2_array:\n",
    "            P2*=1/(sum(relev2_array)+len(relev_array))\n",
    "        else: \n",
    "            P2*= (relev2_array[palavra]+1)/(sum(relev2_array)+len(relev_array))\n",
    "        if palavra not in relev3_array:\n",
    "            P3*=1/(sum(relev3_array)+len(relev_array))\n",
    "        else:\n",
    "            P3*=(relev3_array[palavra]+1/(sum(relev3_array)+len(relev_array)))\n",
    "        P1=P1*pr1\n",
    "        P2=P2*pr2\n",
    "        P3=P3*pr3\n",
    "        x = [P1,P2,P3]\n",
    "        if P1>P2 and P1>P3:\n",
    "            return 1\n",
    "        elif P2>P1 and P2>P3:\n",
    "            return 2\n",
    "        elif P3>P1 and P3>P2:\n",
    "            return 3\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo est√° presente um c√≥digo utilizado por n√≥s para testar a confiabilidade de nosso algoritmo. Logo, inserimos uma frase hipot√©tica para ver como o c√≥digo classifica o referido tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRINDO UMA TABELA DE FREQUENCIA RELATIVA PARA UM TWEET ALEATORIO (FUTURO INPUT)\n",
    "tweet_teste = 'era s√≥ um airpods na minha vida msm, sonho'\n",
    "tweet_teste = tweet_teste.lower()\n",
    "tweet_teste = cleanup(tweet_teste.lower())\n",
    "tweet_teste = pd.Series(tweet_teste.split())\n",
    "tweet_teste_relativo = tweet_teste.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance 1a Iteracao\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, criamos uma fun√ß√£o classificador para testar a performance do algoritmo criado.\n",
    "Logo, ao analisar o tweet, a fun√ß√£o atribui um n√∫mero (1,2 ou 3), referente ao grupo caracter√≠stico que classificou determinado tweet.\n",
    "Tal n√∫mero √© atribu√≠do na coluna classificador na linha do referido tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABRINDO UM DATAFRAME E USANDO O CLASSIFICADOR (CRIANDO NOVO COLUNA DE CLASSIFICADOR NO DATAFRAME)\n",
    "\n",
    "def classificador(df):\n",
    "    df1 = pd.read_excel('{0}'.format(df))\n",
    "    df1['Classificador']= 0\n",
    "    cont = 0\n",
    "    for tweet in df1['Teste']:\n",
    "        tweet = cleanup(str(tweet))\n",
    "        y = robo(tweet,1,1,1)\n",
    "        df1.loc[cont,'Classificador']=y\n",
    "        cont+=1\n",
    "    return df1.loc[:,['Teste','Relevante.1','Classificador']]\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado est√° dispon√≠vel abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevante.1</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>encontrei um que tem airpods em todas as fotos...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>era s√≥ um airpods na minha vida msm, sonho</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o mta de nova york gostaria que voc√™ parasse d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nao sei onde enfiei meus airpods e to tentando...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‚Äúshawn‚Äôs airpods #6‚Äù quantos airpods esse meni...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>era s√≥ um airpods na minha vida mesmo</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>762 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relevante.1  \\\n",
       "0    encontrei um que tem airpods em todas as fotos...          1.0   \n",
       "1           era s√≥ um airpods na minha vida msm, sonho          3.0   \n",
       "2    o mta de nova york gostaria que voc√™ parasse d...          1.0   \n",
       "3    nao sei onde enfiei meus airpods e to tentando...          2.0   \n",
       "4    ‚Äúshawn‚Äôs airpods #6‚Äù quantos airpods esse meni...          1.0   \n",
       "5                era s√≥ um airpods na minha vida mesmo          3.0   \n",
       "..                                                 ...          ...   \n",
       "756                                                NaN          NaN   \n",
       "757                                                NaN          NaN   \n",
       "758                                                NaN          NaN   \n",
       "759                                                NaN          NaN   \n",
       "760                                                NaN          NaN   \n",
       "761                                                NaN          NaN   \n",
       "\n",
       "     Classificador  \n",
       "0                2  \n",
       "1                3  \n",
       "2                3  \n",
       "3                3  \n",
       "4                1  \n",
       "5                3  \n",
       "..             ...  \n",
       "756              1  \n",
       "757              1  \n",
       "758              1  \n",
       "759              1  \n",
       "760              1  \n",
       "761              1  \n",
       "\n",
       "[762 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TESTANDO O CLASSIFICADOR COM O DATAFRAME DE TESTE\n",
    "x = 'airpods1.xlsx'\n",
    "\n",
    "teste =classificador(x)\n",
    "#descomentar a linha abaixo para ver o resultado (dataframe com coluna de classificacao)\n",
    "teste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, fizemos uma fun√ß√£o para verificar a performance do algoritmo feito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tanto, adicionamos uma coluna com os resultados do algoritmo classificador ao nosso dataframe. Em seguida, criamos uma fun√ß√£o que compara a coluna Teste, classifica√ß√£o feita por n√≥s, manual, com a coluna Classificador, feita pelo algoritmo criado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada tweet que a classifica√ß√£o foi a mesma, √© somado 1 ao contador. Ao fim da analise, √© dividido o contador pelo total de tweets.\n",
    "Como resultado, √© apresentada uma porcentagem de acerto do algoritmo comparado com a nossa classifica√ß√£o, que serviu de base para a constitui√ß√£o do algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, a porcentagem de acerto (classifica√ß√£o igual do algoritmo com a nossa atribui√ß√£o do tweet) foi de 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculadora de porcentagem de acertos\n",
    "def calcula_acerto(teste):\n",
    "    i = 0 \n",
    "    contador = 0 \n",
    "    while i < 249:\n",
    "        if teste['Relevante.1'][i]== teste['Classificador'][i]:\n",
    "            contador +=1\n",
    "        i+=1\n",
    "    porcentagem = (contador/248)*100\n",
    "    porcentagem = round(porcentagem)\n",
    "    return ('A porcentagem de acerto foi de {0}%'.format(porcentagem))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A porcentagem de acerto foi de 40%'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcula_acerto(teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alterando o metodo do classificador Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo interseccoes\n",
    "#interseccao tweets relevantes=1 e todos os tweets \n",
    "set_relev1 = set(relev1_array.index)\n",
    "set_relev = set(relev_array.index)\n",
    "inter_R1_RT = set_relev1.intersection(set_relev)\n",
    "lista1 = list(inter_R1_RT)\n",
    "pr1 = len(lista1)/(len(relev_array)) #porcentagem  de palavras que aparecem na interseccao\n",
    "\n",
    "#interseccao tweets relevantes=2 e todos os tweets \n",
    "set_relev2 = set(relev2_array.index)\n",
    "set_relev = set(relev_array.index)\n",
    "inter_R2_RT = set_relev2.intersection(set_relev)\n",
    "lista2 = list(inter_R2_RT)\n",
    "pr2 = len(lista2)/(len(relev_array)) #porcentagem  de palavras que aparecem na interseccao\n",
    "\n",
    "#interseccao tweets relevantes=3 e todos os tweets \n",
    "set_relev3 = set(relev3_array.index)\n",
    "set_relev = set(relev_array.index)\n",
    "inter_R3_RT = set_relev3.intersection(set_relev)\n",
    "lista3 = list(inter_R3_RT)\n",
    "pr3 = len(lista3)/(len(relev_array)) #porcentagem  de palavras que aparecem na interseccao\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robo de probabilidade (agora usando a interseccao para calcular)\n",
    "def robo_1(tweet_teste,P1,P2,P3,pr1,pr2,pr3):\n",
    "    tweet_teste = str(tweet_teste)\n",
    "    tweet_teste = tweet_teste.lower()\n",
    "    tweet_teste = cleanup(tweet_teste)\n",
    "    tweet_teste = removetext(tweet_teste)\n",
    "    tweet_teste = pd.Series(tweet_teste.split())\n",
    "    lista_tweet = list(tweet_teste)\n",
    "    for palavra in lista_tweet:\n",
    "        if palavra not in relev1_array or palavra not in relev2_array or palavra not in relev3_array:\n",
    "            palavra = 1/(sum(relev1_array)+sum(relev2_array)+sum(relev3_array)+len(relev_array))\n",
    "        else:\n",
    "            P1*= (relev1_array[palavra]+1)/(sum(relev1_array)+len(relev_array))\n",
    "            P2*= (relev2_array[palavra]+1)/(sum(relev2_array)+len(relev_array))\n",
    "            P3*= (relev3_array[palavra]+1)/(sum(relev3_array)+len(relev_array))\n",
    "        P1=P1*pr1\n",
    "        P2=P2*pr2\n",
    "        P3=P3*pr3\n",
    "        x = [P1,P2,P3]\n",
    "        if P1>P2 and P1>P3:\n",
    "            return 1\n",
    "        elif P2>P1 and P2>P3:\n",
    "            return 2\n",
    "        elif P3>P1 and P3>P2:\n",
    "            return 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classificador \n",
    "def classificador_1(df,pr1,pr2,pr3):\n",
    "    df1 = pd.read_excel('{0}'.format(df))\n",
    "    df1['Classificador']= 0\n",
    "    cont = 0\n",
    "    for tweet in df1['Teste']:\n",
    "        y = robo_1(tweet,1,1,1,pr1,pr2,pr3)\n",
    "        df1.loc[cont,'Classificador']=y\n",
    "        cont+=1\n",
    "    return df1.loc[:248,['Teste','Relevante.1','Classificador']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rodando o primeiro classificador\n",
    "x = 'airpods1.xlsx'\n",
    "teste1= classificador_1(x,pr1,pr2,pr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando a performance da 2a Iteracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculadora de porcentagem de acerto\n",
    "def calcula_acerto_1(teste):\n",
    "    i = 0\n",
    "    contador = 0 \n",
    "    while i < 249:\n",
    "        if teste['Relevante.1'][i]== teste['Classificador'][i]:\n",
    "            contador +=1\n",
    "        i+=1\n",
    "    porcentagem = (contador/248)*100\n",
    "    porcentagem=round(porcentagem)\n",
    "    return ('A porcentagem de acerto foi de {0}%'.format(porcentagem))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevante.1</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>encontrei um que tem airpods em todas as fotos...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>era s√≥ um airpods na minha vida msm, sonho</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o mta de nova york gostaria que voc√™ parasse d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nao sei onde enfiei meus airpods e to tentando...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‚Äúshawn‚Äôs airpods #6‚Äù quantos airpods esse meni...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>era s√≥ um airpods na minha vida mesmo</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>hoje sonhei que o wani estragou os meus airpod...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>n√£o sabia dos airpods h√° mais de uma semana......</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>nem queria comprar os airpods, mas agora que v...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>preferias comprar 150‚Ç¨ de roupa ou comprar uns...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>os meus airpods chegaram! üòç</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>airpods √© a √∫nica coisa que t√° salvando minha ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relevante.1  \\\n",
       "0    encontrei um que tem airpods em todas as fotos...          1.0   \n",
       "1           era s√≥ um airpods na minha vida msm, sonho          3.0   \n",
       "2    o mta de nova york gostaria que voc√™ parasse d...          1.0   \n",
       "3    nao sei onde enfiei meus airpods e to tentando...          2.0   \n",
       "4    ‚Äúshawn‚Äôs airpods #6‚Äù quantos airpods esse meni...          1.0   \n",
       "5                era s√≥ um airpods na minha vida mesmo          3.0   \n",
       "..                                                 ...          ...   \n",
       "243  hoje sonhei que o wani estragou os meus airpod...          1.0   \n",
       "244  n√£o sabia dos airpods h√° mais de uma semana......          2.0   \n",
       "245  nem queria comprar os airpods, mas agora que v...          3.0   \n",
       "246  preferias comprar 150‚Ç¨ de roupa ou comprar uns...          1.0   \n",
       "247                        os meus airpods chegaram! üòç          3.0   \n",
       "248  airpods √© a √∫nica coisa que t√° salvando minha ...          3.0   \n",
       "\n",
       "     Classificador  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "5                1  \n",
       "..             ...  \n",
       "243              1  \n",
       "244              1  \n",
       "245              1  \n",
       "246              1  \n",
       "247              1  \n",
       "248              1  \n",
       "\n",
       "[249 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A porcentagem de acerto foi de 54%'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = calcula_acerto_1(teste1)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante.1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.457831</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.024096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.208835</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>0.012048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.204819</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.056225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador         1         2         3\n",
       "Relevante.1                                \n",
       "1.0            0.457831  0.008032  0.024096\n",
       "2.0            0.208835  0.020080  0.012048\n",
       "3.0            0.204819  0.008032  0.056225"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(teste1['Relevante.1'],teste1.Classificador,normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
