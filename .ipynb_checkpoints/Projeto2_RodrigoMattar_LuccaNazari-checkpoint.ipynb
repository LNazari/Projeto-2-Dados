{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodrigo Sennati Mattar \n",
    "\n",
    "Lucca Nazari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Lucca Nazari]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O produto escolhido para ser o objeto de estudo no projeto foram os Airpods, fones de ouvido sem fio da Apple.\n",
    "Como base de dados, importamos 750 para base de treinamento, em que nós classificamos os tweets e mais 250 de teste, para validar a eficácia do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'airpods'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 250\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    if msg.full_text.lower()[0] != 'r' and msg.full_text.lower()[1] != 't':\n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(list(set(msgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós dividimos os tweets em 3  classificações diferentes (irrevelante,relevante positivo e relevante negativo). Ao classificar como irrevelante, nós estamos nos referindo a todos os tweets onde não há uma crítica explícita ao produto (aos que somente mencionam o produto). Em relação a segunda classificação, nós estamos nos referindo aos tweets onde houve uma crítica negativa explícita ao produto (como por exemplo os airpods acabam a bateria muito rapido, ou eu perdi meus airpods). A terceira classificação é para os tweets onde há uma crítica positiva explícita ao produto (como por exemplo \"eu só queria um airpods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar os códigos, é necessário importar as bibliotecas pd (pandas) e np (numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "pd.options.display.max_rows = 13 # Escolher quantos prints as funções do pandas fazem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a leitura dos tweets, é necessário \"limpar\" o tweet para que não exista influência de termos indesejados para a análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira \"limpeza\" dos tweets foi realizada pela função cleanup, em que ela recebe uma string e remove todos os sinais de pontuação, vírgulas, pontos de interrogação e exclamação, dois-pontos e etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    punctuation = '[!\\-.:?;,]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, é necessário importar os tweets do excel, através do pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_excel('airpods1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas necessárias para o desenvolvimento do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "from numpy import arange\n",
    "from numpy import percentile\n",
    "import numpy as np\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import string\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, já com os tweets importados e classificados, agrupamos todos os tweets em um único dataframe.\n",
    "Após isso, separamos os tweets com base em sua classificação (1,2 ou 3), para facilitar os códigos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTRANDO TODOS OS TWEETS RELEVENATES\n",
    "relev = tweets.loc[:,['Treinamento','Relevante']]\n",
    "#FILTRANDO OS TWEETS DE ACORDO COM SUA RELEVANCIA (=1,=2,=3)\n",
    "relev1 = tweets.loc[tweets.Relevante==1]\n",
    "relev2 = tweets.loc[tweets.Relevante==2]\n",
    "relev3 = tweets.loc[tweets.Relevante==3]\n",
    "texto_relev1_ = relev1.Treinamento\n",
    "texto_relev2_ = relev2.Treinamento\n",
    "texto_relev3_ = relev3.Treinamento\n",
    "texto_relev = relev.Treinamento\n",
    "\n",
    "#SEPARANDO CADA GRUPO DE RELEVANCIA PARA UM ARQUIVO CSV\n",
    "texto_relev1_.to_csv('relev1.csv', header=True, index=False, encoding='utf-8')\n",
    "texto_relev2_.to_csv('relev2.csv', header=True, index=False, encoding='utf-8')\n",
    "texto_relev3_.to_csv('relev3.csv', header=True, index=False, encoding='utf-8')\n",
    "texto_relev.to_csv('relev.csv', header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo com a \"limpeza\" que foi realizada anteriormente, é necessário remover termos ilegíveis para evitar que o código dê erros.\n",
    "Tal ação foi realizada pela função removetext, abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABRINDO OS ARQUIVOS CSV\n",
    "#primeiro arquivo(relevancia =1)\n",
    "df1 = pd.read_csv('relev1.csv')\n",
    "df1 = df1.dropna(axis=0, how = 'any')\n",
    "#LIMPANDO O TEXTO DE CADA ARQUIVO CSV E DANDO VALUE COUNTS \n",
    "def removetext(text):\n",
    "    return ''.join([i if ord(i) < 128 else '' for i in text])\n",
    "\n",
    "df1['Treinamento'] = df1['Treinamento'].apply(removetext)\n",
    "\n",
    "#segund arquivo(relevancia = 2)\n",
    "df2 = pd.read_csv('relev2.csv')\n",
    "df2 = df2.dropna(axis=0, how = 'any')\n",
    "df2['Treinamento'] = df2['Treinamento'].apply(removetext)\n",
    "\n",
    "\n",
    "#terceiro arquivo (relevancia = 3)\n",
    "df3 = pd.read_csv('relev3.csv')\n",
    "df3 = df3.dropna(axis=0, how = 'any')\n",
    "df3['Treinamento'] = df3['Treinamento'].apply(removetext)\n",
    "\n",
    "#arquivo total\n",
    "dft = pd.read_csv('relev.csv')\n",
    "dft = dft.dropna(axis=0, how = 'any')\n",
    "dft['Treinamento'] = dft['Treinamento'].apply(removetext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, foi desenvolvida a frequência relativa das palavras em relação a cada grupo de relevância, classificados como 1,2,3 e um grupo que contém todos os tweet analisados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRIANDO A TABELA DE FREQUENCIA RELETIVA PARA CADA GRUPO DE RELEVANCIA DE UM TWEET\n",
    "relev1_array = df1['Treinamento'].str.split(' ', expand=True).stack().value_counts()\n",
    "relev2_array = df2['Treinamento'].str.split(' ', expand=True).stack().value_counts()\n",
    "relev3_array = df3['Treinamento'].str.split(' ', expand=True).stack().value_counts()\n",
    "relev_array = dft['Treinamento'].str.split(' ',expand = True).stack().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, antes de classificar os tweets, é necessário separar os tweets em palavras isoladas, que possam ser analisadas individualmente. Assim, as palavras pertencentes a um tweet qualquer, são comparadas com à base de dados, dados do excel já classificados, para que possa ser atribuído a um determinado grupo relevante (1,2 ou 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o caso de uma nova palavra, ou seja, uma palavra que não tenha aparecido na base de dados, a função irá dividir 1 pela soma de todas as palavras no determinado grupo em que a palavra não está presente com todas as palavras presentes no dataframe. Isso foi feito justamente para que a frequência dessa palavra seja muito pequena, visto que por não ter aparecido anteriormente, não terá um peso relevante na análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, para o caso de a palavra já presente na base de dados, a probabilidade será a divisão da frequência relativa da palavra em seu grupo relativo específico pela soma de todas as palavras do grupo específico com todas as palavras analisadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após isso, o algoritmo compara as probabilidades encontradas de o tweet, soma de palavras, estar em cada grupo específico.\n",
    "Como resposta, a função retorna a maior probabilidade entre os trÊs grupos relevantes. Logo, o tweet terá sido classificado como mais provável de ser um tweet irrelevante (1), tweet relevante com crítica negativa (2) ou tweet relevante com crítica positiva (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROBABILIDADE DE UMA PALAVRA EM UM TWEET ALEATORIO (VERIFICAR REPETIDAS)\n",
    "P1 = 1\n",
    "P2 = 1 \n",
    "P3 = 1\n",
    "\n",
    "def robo(tweet_teste,P1,P2,P3):\n",
    "    tweet_teste = str(tweet_teste)\n",
    "    tweet_teste = tweet_teste.lower()\n",
    "    tweet_teste = cleanup(tweet_teste)\n",
    "    tweet_teste = removetext(tweet_teste)\n",
    "    tweet_teste = pd.Series(tweet_teste.split())\n",
    "    lista_tweet = list(tweet_teste)\n",
    "    for palavra in lista_tweet:\n",
    "        if palavra not in relev1_array:\n",
    "            P1*=1/(sum(relev1_array)+len(relev_array))\n",
    "        else: \n",
    "            P1*=(relev1_array[palavra]+1)/(sum(relev1_array)+len(relev_array))\n",
    "        if palavra not in relev2_array:\n",
    "            P2*=1/(sum(relev2_array)+len(relev_array))\n",
    "        else: \n",
    "            P2*= (relev2_array[palavra]+1)/(sum(relev2_array)+len(relev_array))\n",
    "        if palavra not in relev3_array:\n",
    "            P3*=1/(sum(relev3_array)+len(relev_array))\n",
    "        else:\n",
    "            P3*=(relev3_array[palavra]+1/(sum(relev3_array)+len(relev_array)))\n",
    "        P1=P1*pr1\n",
    "        P2=P2*pr2\n",
    "        P3=P3*pr3\n",
    "        x = [P1,P2,P3]\n",
    "        if P1>P2 and P1>P3:\n",
    "            return 1\n",
    "        elif P2>P1 and P2>P3:\n",
    "            return 2\n",
    "        elif P3>P1 and P3>P2:\n",
    "            return 3\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo está presente um código utilizado por nós para testar a confiabilidade de nosso algoritmo. Logo, inserimos uma frase hipotética para ver como o código classifica o referido tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRINDO UMA TABELA DE FREQUENCIA RELATIVA PARA UM TWEET ALEATORIO (FUTURO INPUT)\n",
    "tweet_teste = 'era só um airpods na minha vida msm, sonho'\n",
    "tweet_teste = tweet_teste.lower()\n",
    "tweet_teste = cleanup(tweet_teste.lower())\n",
    "tweet_teste = pd.Series(tweet_teste.split())\n",
    "tweet_teste_relativo = tweet_teste.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance 1a Iteracao\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, criamos uma função classificador para testar a performance do algoritmo criado.\n",
    "Logo, ao analisar o tweet, a função atribui um número (1,2 ou 3), referente ao grupo característico que classificou determinado tweet.\n",
    "Tal número é atribuído na coluna classificador na linha do referido tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABRINDO UM DATAFRAME E USANDO O CLASSIFICADOR (CRIANDO NOVO COLUNA DE CLASSIFICADOR NO DATAFRAME)\n",
    "\n",
    "def classificador(df):\n",
    "    df1 = pd.read_excel('{0}'.format(df))\n",
    "    df1['Classificador']= 0\n",
    "    cont = 0\n",
    "    for tweet in df1['Teste']:\n",
    "        tweet = cleanup(str(tweet))\n",
    "        y = robo(tweet,1,1,1)\n",
    "        df1.loc[cont,'Classificador']=y\n",
    "        cont+=1\n",
    "    return df1.loc[:,['Teste','Relevante.1','Classificador']]\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado está disponível abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevante.1</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>encontrei um que tem airpods em todas as fotos...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>era só um airpods na minha vida msm, sonho</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o mta de nova york gostaria que você parasse d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nao sei onde enfiei meus airpods e to tentando...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“shawn’s airpods #6” quantos airpods esse meni...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>era só um airpods na minha vida mesmo</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>762 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relevante.1  \\\n",
       "0    encontrei um que tem airpods em todas as fotos...          1.0   \n",
       "1           era só um airpods na minha vida msm, sonho          3.0   \n",
       "2    o mta de nova york gostaria que você parasse d...          1.0   \n",
       "3    nao sei onde enfiei meus airpods e to tentando...          2.0   \n",
       "4    “shawn’s airpods #6” quantos airpods esse meni...          1.0   \n",
       "5                era só um airpods na minha vida mesmo          3.0   \n",
       "..                                                 ...          ...   \n",
       "756                                                NaN          NaN   \n",
       "757                                                NaN          NaN   \n",
       "758                                                NaN          NaN   \n",
       "759                                                NaN          NaN   \n",
       "760                                                NaN          NaN   \n",
       "761                                                NaN          NaN   \n",
       "\n",
       "     Classificador  \n",
       "0                2  \n",
       "1                3  \n",
       "2                3  \n",
       "3                3  \n",
       "4                1  \n",
       "5                3  \n",
       "..             ...  \n",
       "756              1  \n",
       "757              1  \n",
       "758              1  \n",
       "759              1  \n",
       "760              1  \n",
       "761              1  \n",
       "\n",
       "[762 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TESTANDO O CLASSIFICADOR COM O DATAFRAME DE TESTE\n",
    "x = 'airpods1.xlsx'\n",
    "\n",
    "teste =classificador(x)\n",
    "#descomentar a linha abaixo para ver o resultado (dataframe com coluna de classificacao)\n",
    "teste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, fizemos uma função para verificar a performance do algoritmo feito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tanto, adicionamos uma coluna com os resultados do algoritmo classificador ao nosso dataframe. Em seguida, criamos uma função que compara a coluna Teste, classificação feita por nós, manual, com a coluna Classificador, feita pelo algoritmo criado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada tweet que a classificação foi a mesma, é somado 1 ao contador. Ao fim da analise, é dividido o contador pelo total de tweets.\n",
    "Como resultado, é apresentada uma porcentagem de acerto do algoritmo comparado com a nossa classificação, que serviu de base para a constituição do algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, a porcentagem de acerto (classificação igual do algoritmo com a nossa atribuição do tweet) foi de 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculadora de porcentagem de acertos\n",
    "def calcula_acerto(teste):\n",
    "    i = 0 \n",
    "    contador = 0 \n",
    "    while i < 249:\n",
    "        if teste['Relevante.1'][i]== teste['Classificador'][i]:\n",
    "            contador +=1\n",
    "        i+=1\n",
    "    porcentagem = (contador/248)*100\n",
    "    porcentagem = round(porcentagem)\n",
    "    return ('A porcentagem de acerto foi de {0}%'.format(porcentagem))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A porcentagem de acerto foi de 40%'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcula_acerto(teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alterando o metodo do classificador Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo interseccoes\n",
    "#interseccao tweets relevantes=1 e todos os tweets \n",
    "set_relev1 = set(relev1_array.index)\n",
    "set_relev = set(relev_array.index)\n",
    "inter_R1_RT = set_relev1.intersection(set_relev)\n",
    "lista1 = list(inter_R1_RT)\n",
    "pr1 = len(lista1)/(len(relev_array)) #porcentagem  de palavras que aparecem na interseccao\n",
    "\n",
    "#interseccao tweets relevantes=2 e todos os tweets \n",
    "set_relev2 = set(relev2_array.index)\n",
    "set_relev = set(relev_array.index)\n",
    "inter_R2_RT = set_relev2.intersection(set_relev)\n",
    "lista2 = list(inter_R2_RT)\n",
    "pr2 = len(lista2)/(len(relev_array)) #porcentagem  de palavras que aparecem na interseccao\n",
    "\n",
    "#interseccao tweets relevantes=3 e todos os tweets \n",
    "set_relev3 = set(relev3_array.index)\n",
    "set_relev = set(relev_array.index)\n",
    "inter_R3_RT = set_relev3.intersection(set_relev)\n",
    "lista3 = list(inter_R3_RT)\n",
    "pr3 = len(lista3)/(len(relev_array)) #porcentagem  de palavras que aparecem na interseccao\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robo de probabilidade (agora usando a interseccao para calcular)\n",
    "def robo_1(tweet_teste,P1,P2,P3,pr1,pr2,pr3):\n",
    "    tweet_teste = str(tweet_teste)\n",
    "    tweet_teste = tweet_teste.lower()\n",
    "    tweet_teste = cleanup(tweet_teste)\n",
    "    tweet_teste = removetext(tweet_teste)\n",
    "    tweet_teste = pd.Series(tweet_teste.split())\n",
    "    lista_tweet = list(tweet_teste)\n",
    "    for palavra in lista_tweet:\n",
    "        if palavra not in relev1_array or palavra not in relev2_array or palavra not in relev3_array:\n",
    "            palavra = 1/(sum(relev1_array)+sum(relev2_array)+sum(relev3_array)+len(relev_array))\n",
    "        else:\n",
    "            P1*= (relev1_array[palavra]+1)/(sum(relev1_array)+len(relev_array))\n",
    "            P2*= (relev2_array[palavra]+1)/(sum(relev2_array)+len(relev_array))\n",
    "            P3*= (relev3_array[palavra]+1)/(sum(relev3_array)+len(relev_array))\n",
    "        P1=P1*pr1\n",
    "        P2=P2*pr2\n",
    "        P3=P3*pr3\n",
    "        x = [P1,P2,P3]\n",
    "        if P1>P2 and P1>P3:\n",
    "            return 1\n",
    "        elif P2>P1 and P2>P3:\n",
    "            return 2\n",
    "        elif P3>P1 and P3>P2:\n",
    "            return 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classificador \n",
    "def classificador_1(df,pr1,pr2,pr3):\n",
    "    df1 = pd.read_excel('{0}'.format(df))\n",
    "    df1['Classificador']= 0\n",
    "    cont = 0\n",
    "    for tweet in df1['Teste']:\n",
    "        y = robo_1(tweet,1,1,1,pr1,pr2,pr3)\n",
    "        df1.loc[cont,'Classificador']=y\n",
    "        cont+=1\n",
    "    return df1.loc[:248,['Teste','Relevante.1','Classificador']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rodando o primeiro classificador\n",
    "x = 'airpods1.xlsx'\n",
    "teste1= classificador_1(x,pr1,pr2,pr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando a performance da 2a Iteracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculadora de porcentagem de acerto\n",
    "def calcula_acerto_1(teste):\n",
    "    i = 0\n",
    "    contador = 0 \n",
    "    while i < 249:\n",
    "        if teste['Relevante.1'][i]== teste['Classificador'][i]:\n",
    "            contador +=1\n",
    "        i+=1\n",
    "    porcentagem = (contador/248)*100\n",
    "    porcentagem=round(porcentagem)\n",
    "    return ('A porcentagem de acerto foi de {0}%'.format(porcentagem))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevante.1</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>encontrei um que tem airpods em todas as fotos...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>era só um airpods na minha vida msm, sonho</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o mta de nova york gostaria que você parasse d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nao sei onde enfiei meus airpods e to tentando...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“shawn’s airpods #6” quantos airpods esse meni...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>era só um airpods na minha vida mesmo</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>hoje sonhei que o wani estragou os meus airpod...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>não sabia dos airpods há mais de uma semana......</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>nem queria comprar os airpods, mas agora que v...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>preferias comprar 150€ de roupa ou comprar uns...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>os meus airpods chegaram! 😍</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>airpods é a única coisa que tá salvando minha ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relevante.1  \\\n",
       "0    encontrei um que tem airpods em todas as fotos...          1.0   \n",
       "1           era só um airpods na minha vida msm, sonho          3.0   \n",
       "2    o mta de nova york gostaria que você parasse d...          1.0   \n",
       "3    nao sei onde enfiei meus airpods e to tentando...          2.0   \n",
       "4    “shawn’s airpods #6” quantos airpods esse meni...          1.0   \n",
       "5                era só um airpods na minha vida mesmo          3.0   \n",
       "..                                                 ...          ...   \n",
       "243  hoje sonhei que o wani estragou os meus airpod...          1.0   \n",
       "244  não sabia dos airpods há mais de uma semana......          2.0   \n",
       "245  nem queria comprar os airpods, mas agora que v...          3.0   \n",
       "246  preferias comprar 150€ de roupa ou comprar uns...          1.0   \n",
       "247                        os meus airpods chegaram! 😍          3.0   \n",
       "248  airpods é a única coisa que tá salvando minha ...          3.0   \n",
       "\n",
       "     Classificador  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "5                1  \n",
       "..             ...  \n",
       "243              1  \n",
       "244              1  \n",
       "245              1  \n",
       "246              1  \n",
       "247              1  \n",
       "248              1  \n",
       "\n",
       "[249 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A porcentagem de acerto foi de 54%'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = calcula_acerto_1(teste1)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante.1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.457831</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.024096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.208835</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>0.012048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.204819</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.056225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador         1         2         3\n",
       "Relevante.1                                \n",
       "1.0            0.457831  0.008032  0.024096\n",
       "2.0            0.208835  0.020080  0.012048\n",
       "3.0            0.204819  0.008032  0.056225"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(teste1['Relevante.1'],teste1.Classificador,normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
